#!/usr/bin/env python3
# tools/robust_backtest_validator.py
"""
ç©©å¥å›æ¸¬é©—è­‰å™¨
- Bootstrap é‡æŠ½æ¨£ï¼ˆä¸å‡è¨­å¸¸æ…‹åˆ†ä½ˆï¼‰
- Trimmed Mean åˆ†æï¼ˆå»é™¤æ¥µç«¯å€¼ï¼‰
- æœ€å·®æƒ…å¢ƒåˆ†æ
- ç©©å¥æ€§è©•åˆ†ç³»çµ±
"""

import numpy as np
from scipy import stats
from typing import List, Dict, Any


class RobustValidator:
    """
    ç©©å¥å›æ¸¬é©—è­‰å™¨
    è§£æ±º 95% CI å‡è¨­å¸¸æ…‹åˆ†ä½ˆèˆ‡æ¥µç«¯å€¼ä¾è³´çš„å•é¡Œ
    """
    
    def __init__(self, n_bootstrap: int = 1000, trim_percent: float = 0.05):
        """
        Args:
            n_bootstrap: Bootstrap é‡æŠ½æ¨£æ¬¡æ•¸
            trim_percent: ä¿®å‰ªæ¯”ä¾‹ï¼ˆå…©ç«¯å„å»é™¤çš„ç™¾åˆ†æ¯”ï¼‰
        """
        self.n_bootstrap = n_bootstrap
        self.trim_percent = trim_percent
    
    # ==================== ä¸»é©—è­‰ä»‹é¢ ====================
    
    def validate(self, returns: List[float]) -> Dict[str, Any]:
        """
        åŸ·è¡Œå®Œæ•´çš„ç©©å¥æ€§é©—è­‰
        
        Args:
            returns: å›å ±ç‡åˆ—è¡¨ï¼ˆ%ï¼‰
            
        Returns:
            åŒ…å«æ‰€æœ‰é©—è­‰çµæœçš„å­—å…¸
        """
        if not returns or len(returns) < 10:
            return {
                'error': 'æ¨£æœ¬æ•¸ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘ 10 å€‹ï¼‰',
                'robustness_score': 0,
                'rating': 'INSUFFICIENT_DATA'
            }
        
        returns_array = np.array(returns)
        
        # 1. Bootstrap åˆ†æ
        bootstrap_ci = self._bootstrap_confidence_interval(returns_array)
        
        # 2. Trimmed Mean åˆ†æ
        trimmed_stats = self._trimmed_analysis(returns_array)
        
        # 3. æœ€å·®æƒ…å¢ƒåˆ†æ
        worst_case = self._worst_case_analysis(returns_array)
        
        # 4. åˆ†ä½ˆç‰¹æ€§åˆ†æ
        distribution = self._distribution_analysis(returns_array)
        
        # 5. ç©©å¥æ€§è©•åˆ†
        robustness_score, rating = self._calculate_robustness_score(
            returns_array, bootstrap_ci, trimmed_stats, worst_case
        )
        
        return {
            'bootstrap_ci': bootstrap_ci,
            'trimmed_stats': trimmed_stats,
            'worst_case': worst_case,
            'distribution': distribution,
            'robustness_score': robustness_score,
            'rating': rating,
            'sample_size': len(returns)
        }
    
    # ==================== Bootstrap é‡æŠ½æ¨£ ====================
    
    def _bootstrap_confidence_interval(
        self, 
        returns: np.ndarray, 
        confidence: float = 0.95
    ) -> Dict[str, float]:
        """
        Bootstrap 95% ä¿¡è³´å€é–“ï¼ˆä¸å‡è¨­åˆ†ä½ˆï¼‰
        """
        bootstrap_means = []
        n = len(returns)
        
        for _ in range(self.n_bootstrap):
            # æœ‰æ”¾å›æŠ½æ¨£
            sample = np.random.choice(returns, size=n, replace=True)
            bootstrap_means.append(np.mean(sample))
        
        # è¨ˆç®—ç™¾åˆ†ä½æ•¸
        alpha = 1 - confidence
        ci_lower = np.percentile(bootstrap_means, (alpha/2) * 100)
        ci_upper = np.percentile(bootstrap_means, (1 - alpha/2) * 100)
        
        return {
            'mean': np.mean(bootstrap_means),
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'std': np.std(bootstrap_means),
            'method': 'Bootstrap'
        }
    
    # ==================== Trimmed Mean åˆ†æ ====================
    
    def _trimmed_analysis(self, returns: np.ndarray) -> Dict[str, float]:
        """
        å»é™¤æ¥µç«¯å€¼çš„ç©©å¥çµ±è¨ˆ
        """
        n = len(returns)
        trim_count = int(n * self.trim_percent)
        
        # æ’åºå¾Œå»é™¤å…©ç«¯
        sorted_returns = np.sort(returns)
        trimmed_returns = sorted_returns[trim_count:n-trim_count]
        
        # è¨ˆç®—ä¿®å‰ªå¾Œçš„çµ±è¨ˆé‡
        trimmed_mean = np.mean(trimmed_returns)
        trimmed_std = np.std(trimmed_returns, ddof=1)
        
        # èˆ‡å®Œæ•´æ¨£æœ¬æ¯”è¼ƒ
        full_mean = np.mean(returns)
        impact = ((trimmed_mean - full_mean) / full_mean * 100) if full_mean != 0 else 0
        
        # æ¥µç«¯å€¼çµ±è¨ˆ
        removed_top = sorted_returns[-trim_count:] if trim_count > 0 else np.array([])
        removed_bottom = sorted_returns[:trim_count] if trim_count > 0 else np.array([])
        
        return {
            'trimmed_mean': trimmed_mean,
            'trimmed_std': trimmed_std,
            'full_mean': full_mean,
            'impact_percent': impact,
            'top_extremes_mean': np.mean(removed_top) if len(removed_top) > 0 else 0,
            'bottom_extremes_mean': np.mean(removed_bottom) if len(removed_bottom) > 0 else 0,
            'trim_percent': self.trim_percent * 100
        }
    
    # ==================== æœ€å·®æƒ…å¢ƒåˆ†æ ====================
    
    def _worst_case_analysis(self, returns: np.ndarray) -> Dict[str, float]:
        """
        åˆ†ææœ€å·® 10% çš„æ¨£æœ¬è¡¨ç¾
        """
        n = len(returns)
        worst_n = max(1, int(n * 0.1))
        
        sorted_returns = np.sort(returns)
        worst_10_percent = sorted_returns[:worst_n]
        
        # é€£çºŒè™§æåˆ†æ
        negative_returns = returns[returns < 0]
        max_consecutive_losses = self._max_consecutive_negative(returns)
        
        return {
            'worst_10_mean': np.mean(worst_10_percent),
            'worst_10_std': np.std(worst_10_percent, ddof=1) if len(worst_10_percent) > 1 else 0,
            'worst_single': np.min(returns),
            'negative_count': len(negative_returns),
            'negative_percent': (len(negative_returns) / n) * 100,
            'max_consecutive_losses': max_consecutive_losses,
            'worst_10_sample_size': len(worst_10_percent)
        }
    
    def _max_consecutive_negative(self, returns: np.ndarray) -> int:
        """è¨ˆç®—æœ€å¤§é€£çºŒè™§ææ¬¡æ•¸"""
        max_streak = 0
        current_streak = 0
        
        for r in returns:
            if r < 0:
                current_streak += 1
                max_streak = max(max_streak, current_streak)
            else:
                current_streak = 0
        
        return max_streak
    
    # ==================== åˆ†ä½ˆç‰¹æ€§åˆ†æ ====================
    
    def _distribution_analysis(self, returns: np.ndarray) -> Dict[str, float]:
        """
        åˆ†ææ”¶ç›Šåˆ†ä½ˆç‰¹æ€§
        """
        # ååº¦ï¼ˆSkewnessï¼‰ï¼šæ­£å€¼=å³åï¼ˆå°‘æ•¸å¤§ç²åˆ©ï¼‰
        skewness = stats.skew(returns)
        
        # å³°åº¦ï¼ˆKurtosisï¼‰ï¼š>3 = è‚¥å°¾åˆ†ä½ˆ
        kurtosis = stats.kurtosis(returns, fisher=False)  # Pearson's definition
        
        # Jarque-Bera å¸¸æ…‹æ€§æª¢é©—
        jb_stat, jb_pvalue = stats.jarque_bera(returns)
        is_normal = jb_pvalue > 0.05  # p > 0.05 æ¥å—å¸¸æ…‹å‡è¨­
        
        return {
            'skewness': skewness,
            'kurtosis': kurtosis,
            'is_normal_distribution': is_normal,
            'jb_pvalue': jb_pvalue,
            'distribution_type': self._classify_distribution(skewness, kurtosis, is_normal)
        }
    
    def _classify_distribution(self, skew: float, kurt: float, is_normal: bool) -> str:
        """åˆ†é¡åˆ†ä½ˆé¡å‹"""
        if is_normal:
            return 'Normal'
        elif abs(skew) > 1 and kurt > 5:
            return 'Fat-Tailed (Extreme Events)'
        elif skew > 0.5:
            return 'Right-Skewed (Few Large Wins)'
        elif skew < -0.5:
            return 'Left-Skewed (Few Large Losses)'
        elif kurt > 5:
            return 'Heavy-Tailed'
        else:
            return 'Non-Normal'
    
    # ==================== ç©©å¥æ€§è©•åˆ† ====================
    
    def _calculate_robustness_score(
        self,
        returns: np.ndarray,
        bootstrap_ci: Dict,
        trimmed_stats: Dict,
        worst_case: Dict
    ) -> tuple[float, str]:
        """
        è¨ˆç®—ç©©å¥æ€§è©•åˆ†ï¼ˆ0-100ï¼‰
        
        è©•åˆ†æ¨™æº–ï¼š
        - 30 åˆ†ï¼šBootstrap CI ä¸‹ç•Œç‚ºæ­£
        - 25 åˆ†ï¼šTrimmed Mean ç‚ºæ­£
        - 20 åˆ†ï¼šæœ€å·® 10% æ¨£æœ¬ä¸éåº¦è™§æ
        - 15 åˆ†ï¼šæ­£å ±é…¬å€é–“æ¯”ä¾‹é«˜
        - 10 åˆ†ï¼šæœ€å¤§é€£çºŒè™§æå¯æ§
        """
        score = 0.0
        
        # 1. Bootstrap CI ä¸‹ç•Œ (30 åˆ†)
        if bootstrap_ci['ci_lower'] > 0:
            score += 30
        elif bootstrap_ci['ci_lower'] > -5:
            score += 15
        
        # 2. Trimmed Mean (25 åˆ†)
        if trimmed_stats['trimmed_mean'] > 0:
            score += 25
        elif trimmed_stats['trimmed_mean'] > -5:
            score += 12
        
        # 3. æœ€å·® 10% æ¨£æœ¬ (20 åˆ†)
        worst_mean = worst_case['worst_10_mean']
        if worst_mean > -10:
            score += 20
        elif worst_mean > -20:
            score += 10
        elif worst_mean > -30:
            score += 5
        
        # 4. æ­£å ±é…¬æ¯”ä¾‹ (15 åˆ†)
        positive_percent = 100 - worst_case['negative_percent']
        if positive_percent >= 70:
            score += 15
        elif positive_percent >= 50:
            score += 10
        elif positive_percent >= 40:
            score += 5
        
        # 5. æœ€å¤§é€£çºŒè™§æ (10 åˆ†)
        max_losses = worst_case['max_consecutive_losses']
        if max_losses <= 3:
            score += 10
        elif max_losses <= 5:
            score += 7
        elif max_losses <= 7:
            score += 4
        
        # è©•ç´š
        if score >= 80:
            rating = 'Excellent â­â­â­â­â­'
        elif score >= 65:
            rating = 'Good â­â­â­â­'
        elif score >= 50:
            rating = 'Fair â­â­â­'
        elif score >= 35:
            rating = 'Poor â­â­'
        else:
            rating = 'Very Poor â­'
        
        return score, rating
    
    # ==================== å ±å‘Šç”Ÿæˆ ====================
    
    def generate_report(self, results: Dict[str, Any], strategy_name: str = '') -> str:
        """
        ç”Ÿæˆæ–‡å­—å ±å‘Š
        """
        if 'error' in results:
            return f"âŒ {results['error']}"
        
        report = []
        report.append("=" * 70)
        report.append(f"ğŸ”’ ç©©å¥æ€§é©—è­‰å ±å‘Š{' - ' + strategy_name if strategy_name else ''}")
        report.append("=" * 70)
        
        # Bootstrap CI
        bs = results['bootstrap_ci']
        report.append(f"\nğŸ“Š Bootstrap ä¿¡è³´å€é–“ï¼ˆ{self.n_bootstrap} æ¬¡é‡æŠ½æ¨£ï¼‰ï¼š")
        report.append(f"  å¹³å‡: {bs['mean']:.2f}%")
        report.append(f"  95% CI: [{bs['ci_lower']:.2f}%, {bs['ci_upper']:.2f}%]")
        report.append(f"  æ¨™æº–å·®: {bs['std']:.2f}%")
        
        # Trimmed Mean
        tm = results['trimmed_stats']
        report.append(f"\nğŸ“‰ å»é™¤æ¥µç«¯å€¼åˆ†æï¼ˆä¿®å‰ª {tm['trim_percent']:.0f}%ï¼‰ï¼š")
        report.append(f"  å®Œæ•´æ¨£æœ¬å¹³å‡: {tm['full_mean']:.2f}%")
        report.append(f"  ä¿®å‰ªå¾Œå¹³å‡: {tm['trimmed_mean']:.2f}%")
        report.append(f"  æ¥µç«¯å€¼å½±éŸ¿: {tm['impact_percent']:+.2f}%")
        if abs(tm['impact_percent']) > 20:
            report.append(f"  âš ï¸ ç­–ç•¥é«˜åº¦ä¾è³´æ¥µç«¯å€¼")
        
        # Worst Case
        wc = results['worst_case']
        report.append(f"\nâš ï¸ æœ€å·®æƒ…å¢ƒåˆ†æï¼š")
        report.append(f"  æœ€å·® 10% å¹³å‡: {wc['worst_10_mean']:.2f}%")
        report.append(f"  æœ€å·®å–®æ¬¡: {wc['worst_single']:.2f}%")
        report.append(f"  è² å ±é…¬æ¯”ä¾‹: {wc['negative_percent']:.1f}%")
        report.append(f"  æœ€å¤§é€£çºŒè™§æ: {wc['max_consecutive_losses']} æ¬¡")
        
        # Distribution
        dist = results['distribution']
        report.append(f"\nğŸ“ åˆ†ä½ˆç‰¹æ€§ï¼š")
        report.append(f"  é¡å‹: {dist['distribution_type']}")
        report.append(f"  ååº¦: {dist['skewness']:.2f}")
        report.append(f"  å³°åº¦: {dist['kurtosis']:.2f}")
        if not dist['is_normal_distribution']:
            report.append(f"  âš ï¸ éå¸¸æ…‹åˆ†ä½ˆï¼ˆt-test å¯èƒ½ä¸æº–ç¢ºï¼‰")
        
        # Robustness Score
        report.append(f"\nğŸ¯ ç©©å¥æ€§è©•åˆ†ï¼š")
        report.append(f"  åˆ†æ•¸: {results['robustness_score']:.1f}/100")
        report.append(f"  è©•ç´š: {results['rating']}")
        report.append(f"  æ¨£æœ¬æ•¸: {results['sample_size']}")
        
        report.append("=" * 70)
        
        return "\n".join(report)


# ==================== æ¸¬è©¦å‡½æ•¸ ====================

def test_validator():
    """æ¸¬è©¦é©—è­‰å™¨åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦ç©©å¥å›æ¸¬é©—è­‰å™¨\n")
    
    validator = RobustValidator(n_bootstrap=1000)
    
    # æ¸¬è©¦ 1: å¸¸æ…‹åˆ†ä½ˆ
    print("æ¸¬è©¦ 1: å¸¸æ…‹åˆ†ä½ˆæ•¸æ“š")
    normal_returns = np.random.normal(10, 20, 100).tolist()
    result1 = validator.validate(normal_returns)
    print(validator.generate_report(result1, "Normal Distribution Test"))
    
    print("\n\n")
    
    # æ¸¬è©¦ 2: è‚¥å°¾åˆ†ä½ˆï¼ˆæ¨¡æ“¬çœŸå¯¦äº¤æ˜“ï¼‰
    print("æ¸¬è©¦ 2: è‚¥å°¾åˆ†ä½ˆï¼ˆæ¨¡æ“¬çœŸå¯¦ç­–ç•¥ï¼‰")
    fat_tail_returns = np.concatenate([
        np.random.normal(-3, 8, 70),    # 70% å°è™§æ/å°ç²åˆ©
        np.random.normal(15, 15, 20),   # 20% ä¸­ç­‰ç²åˆ©
        np.random.normal(80, 40, 10)    # 10% å¤§ç²åˆ©ï¼ˆæ¥µç«¯å€¼ï¼‰
    ]).tolist()
    result2 = validator.validate(fat_tail_returns)
    print(validator.generate_report(result2, "Fat-Tail Distribution Test"))


if __name__ == "__main__":
    test_validator()
